{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments\n",
    "1. 从基础概率推导贝叶斯公式，朴素贝叶斯公式(1)\n",
    "2. 学习先验概率(2)\n",
    "3. 学习后验概率(3)\n",
    "4. 学习LR和linear regreeesion之间的区别(4)\n",
    "5. 推导sigmoid function公式(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classfication\n",
    "### 1. Target\n",
    "find a function, which can divide the training data into a number of different classes. There are many applications such as credit scoring, medical dignosis, handwritten digit recognition and so on.\n",
    "### 2. Model \n",
    "Through the course of Lee, we have learned that both regression model and ideal replace model have its own weakness, either on the bad fit on training data, or on the lack of derivatives. So we apply probabilistic model to discuss classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The theory of probabilistic model\n",
    "#### 3.1 盒子抽取概率举例\n",
    "场景：有两个大小一致的盒子，每个盒子中有5个球。其中，盒子1中有4个蓝色的球和1个白色的球，盒子2中有1个蓝色的球和4个白色的球；\n",
    "\n",
    "已知在随机抽样过程中，抽到第一个盒子的概率是2/3,记作P(B1),抽到第二个盒子的概率是1/3，记作P(B2);\n",
    "\n",
    "对盒子1:随机抽取一个球，蓝球的概率为4/5，记作P(Blue|B1),白色球的概率是1/5，记作P(W|B1)\n",
    "\n",
    "对盒子2:随机抽取一个球，蓝球的概率为1/5，记作P(Blue|B2),白色球的概率是4/5，记作P(W|B2)\n",
    "\n",
    "<table>\n",
    "<td>\n",
    "<img src=\"images/box.JPG\" style=\"width:250;height:300px;\">\n",
    "\n",
    "</td>\n",
    "\n",
    "</table>\n",
    "\n",
    "问题：随机从两个盒子中抽一个球，抽到的蓝色球是盒子2中的概率是多少？（根据公式计算，答案很明显）\n",
    "$$ P(B2|Blue)=\\frac{P(Blue|B2)P(B2)}{P(Blue|B2)P(B2)+P(Blue|B1)P(B1)}$$\n",
    "\n",
    "### 3.2  概率和分类的类比关系\n",
    "如3.1 节解释，分类问题可以与概率问题相类比：\n",
    "\n",
    "1) 不同的盒子类比于不同的类别，即分类个数\n",
    "\n",
    "2) 随机抽取一个球，判断此球属于哪个盒子的概率，类比于随机给定一个数据X，得到X属于不同类别的概率；\n",
    "\n",
    "3) 判定X属于概率较大的那一类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 朴素贝叶斯法学习基本概率\n",
    "eg:设输入空间X为N维向量的集合，输出空间维分类集合Y={c1,c2,...ck},P(X,Y)为X，Y的联合概率分布，训练数据T={(x1,y1),(x2,y2),...(xn,yn)}\n",
    "\n",
    "先验概率：P(Y=ck),k=1,2,3...n，即从已知的历史数据中获得，是‘提前’知道的\n",
    "\n",
    "联合概率分布 P(X=x,Y=y), 其中x,y为训练数据对\n",
    "\n",
    "后验概率：P(Y|X) 是根据朴素贝叶斯法学习到的模型计算出来的，也是分类问题的解\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 高斯分布\n",
    "<table>\n",
    "<td>\n",
    "<img src=\"images/guaa.JPG\" style=\"width:250;height:300px;\">\n",
    "\n",
    "</td>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用高斯分布处理分类问题的基本思路：模型已定，参数mu和sigma未知。\n",
    "\n",
    "首先，高斯公式表示的是多维空间中x取特定值被选中的概率(准确说是x的一种分布，不是概率，但是跟概率相关)\n",
    "\n",
    "其次，根据多个训练数据，可以得到参数mu和sigma；\n",
    "\n",
    "最后，根据预测的参数值，求得未知点x的概率\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 最大似然估计\n",
    "<table>\n",
    "<td>\n",
    "<img src=\"images/max.JPG\" style=\"width:250;height:300px;\">\n",
    "\n",
    "</td>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 如何利用高斯分布进行分类\n",
    "<table>\n",
    "<td>\n",
    "<img src=\"images/reclass.JPG\" style=\"width:250;height:300px;\">\n",
    "\n",
    "</td>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 概率模型建立\n",
    "<table>\n",
    "<td>\n",
    "<img src=\"images/steps.JPG\" style=\"width:250;height:300px;\">\n",
    "\n",
    "</td>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 后验概率\n",
    "朴素贝叶斯法对条件概率分布作了条件独立性的假设，即条件独立假设等于是说用于分类的特征在类确定的条件下都是条件独立的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Guassian_NB:\n",
    "    def __init__(self):\n",
    "        self.model=None\n",
    "    @staticmethod\n",
    "    #parameter X is a list\n",
    "    def mean(x):\n",
    "        return sum(x)/float(len(x))\n",
    "    \n",
    "    def std(self,x):\n",
    "        avg=self.mean(x)\n",
    "        std=sum((i-avg)**2 for i in x)/float(len(x))\n",
    "        return std\n",
    "    \n",
    "    #===split train data by ylabel\n",
    "    def getparams(self,X):\n",
    "        summary=[(self.mean(data),self.std(data)) for data in zip(*X)]\n",
    "        return summary\n",
    "   \n",
    "    def guassian_probablity(self,x,mean,std):\n",
    "        exponet=(x-mean)**2/(2*std*std)\n",
    "        probablity=np.exp(-exponet)/(2*np.pi*std*std)**0.5\n",
    "        return probablity\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        labels=set(y)\n",
    "        data={label:[] for label in labels}\n",
    "        for f,label in zip(X,y):\n",
    "            data[label].append(f)\n",
    "        self.model={label:self.getparams(value) for label,value in data.items()}\n",
    "        return 'guassian train done'\n",
    "        \n",
    "    def cal_guassian_pro(self,input_data):\n",
    "        probably={}\n",
    "        for label,value in self.model.items():\n",
    "            probably[label]=1.0\n",
    "            for i in range(len(value)):\n",
    "                (mean,std)=value[i]\n",
    "                probably[label]*=self.guassian_probablity(input_data[i],mean,std)\n",
    "        return probably\n",
    "    \n",
    "    def predict(self,test):\n",
    "        pred=sorted(self.cal_guassian_pro(test).items(),key=lambda x:x[1],reverse=True)\n",
    "        return pred[0][0]\n",
    "    \n",
    "    def score(self,X_test,y_test):\n",
    "        count=0\n",
    "        m=len(y_test)\n",
    "        for i in range(m):\n",
    "            if self.predict(X_test[i])==y_test[i]:\n",
    "                count+=1\n",
    "        accuracy=count/m\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare definiton function with sklearn function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris=datasets.load_iris()\n",
    "X=iris['data']\n",
    "y=iris['target']\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "clf=GaussianNB()\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.score(X_test,y_test))\n",
    "\n",
    "model=Guassian_NB()\n",
    "model.fit(X_train,y_train)\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 高斯公式推导\n",
    "<table>\n",
    "<td>\n",
    "<img src=\"images/3.jpg\" style=\"width:250;height:300px;\">\n",
    "\n",
    "</td>\n",
    "\n",
    "</table>\n",
    "<table>\n",
    "<td>\n",
    "<img src=\"images/4.jpg\" style=\"width:250;height:300px;\">\n",
    "\n",
    "</td>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 logistic regression\n",
    "### 4.1 分类问题的函数集\n",
    "3.6节介绍了如何利用高斯分布进行分类，得到用于分类的函数集：\n",
    "<table>\n",
    "<td>\n",
    "<img src=\"images/sigmoid.jpg\" style=\"width:250;height:300px;\">\n",
    "\n",
    "</td>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Logistic regression and linear regerssion\n",
    "\n",
    "1) 分类的函数集\n",
    "\n",
    "logistci regression： $$ L(w,b)=\\sigma(\\sum_{i=1}^{n}{w_i*x_i+b})$$\n",
    "\n",
    "linear regression: $$L(w,b)=\\sum_{i=1}^{n}{w_i*x_i+b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 满足条件的最优解\n",
    "\n",
    "以二分类问题为例，训练数据输入$(x_1,x_2,...x_i,...,x_n)$，输出标签$(y_1,y_2,...,y_i,...y_n)$\n",
    "\n",
    "假设生成的数据满足 $𝑓(𝑤,𝑏,x) = P_(w,b)(C1 \\mid X)$,给定W，b的数据集，寻找最优解\n",
    "\n",
    "损失函数： $$𝐿(𝑤,𝑏) = f(x^1)f(x^2)(1-f(x^3))...f(x^n)$$\n",
    "\n",
    "$$𝑤^*,𝑏^*= 𝑎𝑟𝑔 max 𝐿(𝑤,b)=arg min-lnL(w,b)$$\n",
    "\n",
    "$$lnL(w,b)=lnf(x^1)+lnf(x^2)+ln(1-f(x^3)+...lnf(x^n)$$\n",
    "\n",
    "<table>\n",
    "<td>\n",
    "<img src=\"images/loss_1.jpg\" style=\"width:250;height:300px;\">\n",
    "\n",
    "</td>\n",
    "\n",
    "</table>\n",
    "<table>\n",
    "<td>\n",
    "<img src=\"images/loss_2.jpg\" style=\"width:250;height:300px;\">\n",
    "\n",
    "</td>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据数学推导，可以得出logistic regression 和linear regression 之间的区别汇总如下\n",
    "<td>\n",
    "<img src=\"images/best.jpg\" style=\"width:250;height:300px;\">\n",
    "\n",
    "</td>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么logistic regression 不用平方误差求损失函数？\n",
    "\n",
    "<td>\n",
    "<img src=\"images/square.jpg\" style=\"width:250;height:300px;\">\n",
    "\n",
    "</td>\n",
    "\n",
    "</table>\n",
    "\n",
    "从微分关系可以看出，如果损失函数是交叉熵，距离target越远，微分值就越大，就可以做到距离target越远，更新参数越快。\n",
    "而平方误差在距离target很远的时候，微分值非常小，会造成移动的速度非常慢，无法实现快速到达最小值的位置。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
