{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树问题\n",
    "决策树模型通过递归方法生成决策树，直到满足基线条件。这种方法生成的决策树，存在过拟合问题。比较行之有效的方法是考虑算法的复杂度后，对决策树进行剪枝。\n",
    "\n",
    "剪枝是对已经生成的决策树进行简化的过程，这个过程可能是删除部分子结点，也可能是将多个父节点合并，需要依据具体情况而定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART\n",
    "分类与回归树（classification and regression tree， CART） 模型由Breiman等人在1984年提出， 是应用广泛的决策树学习方法。 CART同样由特征选择、 树的生成及剪枝组成，既可以用于分类也可以用于回归。\n",
    "\n",
    "CART算法主要包括生成决策树和对决策树进行剪枝。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART生成\n",
    "本小节主要介绍分类树的生成。\n",
    "### 基尼指数：\n",
    "分类问题中，假设有K个类，样本点属于第k类的概率为pk，则概率分布的基尼指数定义为：$Gini(p)=\\sum_{k=1}^{K}{p_k*(1-p_k)}$\n",
    "\n",
    "给定样本集D,其基尼指数为：$Gini(D)=1-\\sum_{k=1}^{K}{(\\frac{|C_k|}{|D|})^2}$\n",
    "\n",
    "如果样本集合D根据特征A是否取某一可能值a被分割成D1和D2两部分，即 D1={(x,y)in D|A(x)=a} D2=D-D1\n",
    "\n",
    "则在特征A的条件下， 集合D的基尼指数定义为:\n",
    "\n",
    "$Gini(D,A)=\\frac{|D1|}{|D|}Gini(D1)+\\frac{|D2|}{|D|}Gini(D2)$\n",
    "\n",
    "基尼指数Gini(D)表示集合D的不确定性， 基尼指数Gini(D,A)表示经A＝a分割后集合D的不确定性。基尼指数值越大，样本集合的不确定性也就越大。\n",
    "\n",
    "### 算法实现\n",
    "(1) 设结点的训练数据集为D，计算现有特征对该数据集的基尼指数。对每一个特征A，对其可能取的每个值a，\n",
    "根据样本点对A＝a的测试为“是”或“否”将D分割成D1和D2两部分,计算A＝a时的基尼指数。\n",
    "\n",
    "(2) 在所有可能的特征A以及它们所有可能的切分点a中，选择基尼指数最小的特征及其对应的切分点作为最优特征与最优切分点。 依最优特征与最优切分\n",
    "点， 从现结点生成两个子结点， 将训练数据集依特征分配到两个子结点中去。\n",
    "\n",
    "(3) 对两个子结点递归地调用(1),(2)直至满足停止条件。\n",
    "\n",
    "(4) 生成CART决策树。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归树生成\n",
    "假设X与Y分别为输入和输出变量，并且Y是连续变量，给定训练数据集D{(x1,y1),(x2,y2),(x3,y3),...(xN,yN)}\n",
    "\n",
    "假设已将输入空间划分为M个单元R1,R2,…,RM,并且在每个单元Rm上有一个固定的输出值cm， 于是回归树模型可表示为:\n",
    "\n",
    "$$f(x)=\\sum_{m=1}^{M}{C_m*I(x\\in R_m)}$$\n",
    "\n",
    "当输入空间的划分确定时， 可以用平方误差 $\\sum_{x_i \\in R_m}{(y_i-f(x_i))^2}$ 来表示回归是对于训练数据的预测误差。用平方误差最小的准则求解每个单元上的最优输出值。一般情况下单元Rm上的cm的最优值是Rm上的所有输入实例xi对应的输出yi的均值，\n",
    "即 $\\hat C_m=mean(y_i|x_i \\in R_m)$\n",
    "\n",
    "#### 空间划分\n",
    "选择第j个变量x(j)和它取的值s， 作为切分变量（splitting variable）和切分点（splitting point）并定义两个区域：\n",
    "\n",
    "$R_1(j,s)={[x|x^{(j)}\\le s]}$ 和$ R_2(j,s)={[x|x^{(j)}> s]}$, 然后寻找最优切分变量j和最优切分点s。 \n",
    "\n",
    "$$min_{j,s}[min_{c_1}\\sum_{x_i \\in R_1(j,s)}{(y_i-c_1)^2}+min_{c_2}\\sum_{x_i \\in R_2(j,s)}{(y_i-c_2)^2}]$$\n",
    "\n",
    "对固定输入变量j可以找到最优切分点s $\\hat C_1=mean(y_i|x_i \\in R_1(j,s))$, $\\hat C_2=mean(y_i|x_i \\in R_2(j,s))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最小二乘回归树生成算法\n",
    "\n",
    "(1) 选择最优切分变量j与切分点s， 求解\n",
    "\n",
    "$min_{j,s}[min_{c_1}\\sum_{x_i \\in R_1(j,s)}{(y_i-c_1)^2}+min_{c_2}\\sum_{x_i \\in R_2(j,s)}{(y_i-c_2)^2}]$\n",
    "\n",
    "遍历变量j， 对固定的切分变量j扫描切分点s， 选择使上式达到最小值的对（j,s）\n",
    "\n",
    "(2) 用选定的对（j,s） 划分区域并决定相应的输出值：\n",
    "\n",
    "$R_1(j,s)={[x|x^{(j)}\\le s]}$ 和$ R_2(j,s)={[x|x^{(j)}> s]}$ $\\hat C_m=\\frac{1}{N_m}\\sum_{x_i \\in R_m(j,s)}{y_i}$\n",
    "\n",
    "(3) 继续对两个子区域调用步骤(1),(2)直至满足停止条件。\n",
    "\n",
    "(4) 将输入空间划分为M个区域R1,R2,…Rm， 生成决策树：\n",
    "\n",
    "$$f(x)=\\sum_{m=1}^{M}{C_m*I(x\\in R_m)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART剪枝\n",
    "算法实现：\n",
    "已知：CART算法生成的决策树T0，求解通过剪枝得到最优决策树Ta。\n",
    "\n",
    "(1) 设k＝0， T＝T0。\n",
    "\n",
    "(2) 设$a=\\propto $\n",
    "\n",
    "(3) 自下而上地对各内部结点t计算C(Tt),|Tt|以及$g(t)=\\frac{C(t)-C(T_t)}{|T_t|-1}$这里，Tt表示以t为根结点的子树， C(Tt)是对训练数据的预测误差，|Tt|是Tt的叶结点个数。\n",
    "\n",
    "(4) 自上而下地访问内部结点t， 如果有g(t)＝a， 进行剪枝， 并对叶结点t以多数表决法决定其类， 得到树T。\n",
    "\n",
    "(5) 设k＝k+1， ak＝a， Tk＝T。\n",
    "\n",
    "(6) 如果T不是由根结点单独构成的树， 则回到步骤（4）\n",
    "\n",
    "(7)采用交叉验证法在子树序列T0,T1,…,Tn中选取最优子树Ta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
